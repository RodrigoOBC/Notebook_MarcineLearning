{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZIK7ehqFx5I+fq10GDfrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoOBC/Notebook_MarcineLearning/blob/master/Rede_Neural_predizer_vendas_bicicleta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFo3rIhEDJmO"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torch import optim\r\n",
        "\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLnVxOPXDQS6",
        "outputId": "4071bf13-907a-4d3f-fc91-959f9960f0d4"
      },
      "source": [
        "args = {\r\n",
        "    'epoch_num': 200,     # Número de épocas.\r\n",
        "    'lr': 5e-5,           # Taxa de aprendizado.\r\n",
        "    'weight_decay': 5e-4, # Penalidade L2 (Regularização).\r\n",
        "    'num_workers': 3,     # Número de threads do dataloader.\r\n",
        "    'batch_size': 20,     # Tamanho do batch.\r\n",
        "}\r\n",
        "\r\n",
        "if torch.cuda.is_available():\r\n",
        "    args['device'] = torch.device('cuda')\r\n",
        "else:\r\n",
        "    args['device'] = torch.device('cpu')\r\n",
        "\r\n",
        "print(args['device'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4LQT_j9DSkD",
        "outputId": "b941de1e-e74f-41f4-93ae-c21394446192"
      },
      "source": [
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\r\n",
        "! unzip Bike-Sharing-Dataset.zip\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-12 22:23:48--  https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 279992 (273K) [application/x-httpd-php]\n",
            "Saving to: ‘Bike-Sharing-Dataset.zip’\n",
            "\n",
            "Bike-Sharing-Datase 100%[===================>] 273.43K   996KB/s    in 0.3s    \n",
            "\n",
            "2020-12-12 22:23:49 (996 KB/s) - ‘Bike-Sharing-Dataset.zip’ saved [279992/279992]\n",
            "\n",
            "Archive:  Bike-Sharing-Dataset.zip\n",
            "  inflating: Readme.txt              \n",
            "  inflating: day.csv                 \n",
            "  inflating: hour.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DEL6coEwDYo2",
        "outputId": "ee6d1084-81f2-4efc-c434-01a7566aee3a"
      },
      "source": [
        "df = pd.read_csv('hour.csv')\r\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "0        1  2011-01-01       1   0  ...        0.0       3          13   16\n",
              "1        2  2011-01-01       1   0  ...        0.0       8          32   40\n",
              "2        3  2011-01-01       1   0  ...        0.0       5          27   32\n",
              "3        4  2011-01-01       1   0  ...        0.0       3          10   13\n",
              "4        5  2011-01-01       1   0  ...        0.0       0           1    1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnZnEnXiDdh8"
      },
      "source": [
        "torch.manual_seed(1)\r\n",
        "indices = torch.randperm(len(df)).tolist()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqa76suyD9dz"
      },
      "source": [
        "train_size = int(0.8*len(df))\r\n",
        "df_train = df.iloc[indices[:train_size]]\r\n",
        "df_test  = df.iloc[indices[train_size:]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qHxBxAeqEBMg",
        "outputId": "89298c69-eb8a-411d-f4bc-789f544bb30a"
      },
      "source": [
        "display(df_test.head())\r\n",
        "df_train.to_csv('bike_train.csv',index=False)\r\n",
        "df_test.to_csv('bike_test.csv',index=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12663</th>\n",
              "      <td>12664</td>\n",
              "      <td>2012-06-16</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.6212</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.1940</td>\n",
              "      <td>123</td>\n",
              "      <td>229</td>\n",
              "      <td>352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1801</th>\n",
              "      <td>1802</td>\n",
              "      <td>2011-03-20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.3939</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.3582</td>\n",
              "      <td>58</td>\n",
              "      <td>98</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16567</th>\n",
              "      <td>16568</td>\n",
              "      <td>2012-11-28</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.2239</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8817</th>\n",
              "      <td>8818</td>\n",
              "      <td>2012-01-08</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1045</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2608</th>\n",
              "      <td>2609</td>\n",
              "      <td>2011-04-23</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.5455</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.3582</td>\n",
              "      <td>182</td>\n",
              "      <td>209</td>\n",
              "      <td>391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "12663    12664  2012-06-16       2   1  ...     0.1940     123         229  352\n",
              "1801      1802  2011-03-20       1   0  ...     0.3582      58          98  156\n",
              "16567    16568  2012-11-28       4   1  ...     0.2239       0          12   12\n",
              "8817      8818  2012-01-08       1   1  ...     0.1045       0           2    2\n",
              "2608      2609  2011-04-23       2   0  ...     0.3582     182         209  391\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSLsOt5jEFYL"
      },
      "source": [
        "class Bicicletas(Dataset):\r\n",
        "  def __init__(self, csv_path, scaler_feat=None, scaler_label=None):\r\n",
        "    self.dados = pd.read_csv(csv_path).to_numpy()\r\n",
        "    \r\n",
        "  def __getitem__(self, idx):\r\n",
        "    \r\n",
        "    sample = self.dados[idx][2:14]\r\n",
        "    target  = self.dados[idx][-1:]\r\n",
        "    \r\n",
        "    # converte para tensor\r\n",
        "    sample = torch.from_numpy(sample.astype(np.float32))\r\n",
        "    target  = torch.from_numpy(target.astype(np.float32))\r\n",
        "    \r\n",
        "    return sample, target\r\n",
        "    \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.dados)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZWjbRqiEzUM"
      },
      "source": [
        "df_train = Bicicletas('bike_train.csv')\r\n",
        "df_test = Bicicletas('bike_test.csv')\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxB9ia3mGGh8",
        "outputId": "9a70e812-fdb2-4768-ca04-6c2b76791710"
      },
      "source": [
        "df_train[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 4.0000,  1.0000, 11.0000, 19.0000,  0.0000,  4.0000,  1.0000,  1.0000,\n",
              "          0.3800,  0.3939,  0.2700,  0.3582]), tensor([373.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3bkjQ2eGPIS"
      },
      "source": [
        "train_loader = DataLoader(df_train,\r\n",
        "                          args['batch_size'],\r\n",
        "                          num_workers=args['num_workers'],\r\n",
        "                          shuffle=True)\r\n",
        "test_loader = DataLoader(df_test,\r\n",
        "                         args['batch_size'],\r\n",
        "                         num_workers=args['num_workers'],\r\n",
        "                         shuffle=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYyLG7efGeeT",
        "outputId": "e6e5f888-8b4a-4482-cdd8-36b6478bd134"
      },
      "source": [
        "for batch in test_loader:\r\n",
        "  \r\n",
        "  dado, rotulo = batch\r\n",
        "  print('## Dimensionalidade do batch ##')\r\n",
        "  print(dado.size(), rotulo.size())\r\n",
        "  \r\n",
        "  break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Dimensionalidade do batch ##\n",
            "torch.Size([20, 12]) torch.Size([20, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf_xaWY_GpiL"
      },
      "source": [
        "class MLP(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self, input_size, hidden_size, out_size):\r\n",
        "    super(MLP, self).__init__()\r\n",
        "    \r\n",
        "    self.features = nn.Sequential(\r\n",
        "          nn.Linear(input_size, hidden_size),\r\n",
        "          nn.ReLU(),\r\n",
        "          nn.Linear(hidden_size, hidden_size),\r\n",
        "          nn.ReLU(),\r\n",
        "    )\r\n",
        "    \r\n",
        "    self.classifier = nn.Sequential(\r\n",
        "        nn.Linear(hidden_size, out_size),\r\n",
        "        nn.ReLU(),\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, X):\r\n",
        "    \r\n",
        "    hidden = self.features(X)\r\n",
        "    output = self.classifier(hidden)\r\n",
        "    \r\n",
        "    return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk-_6Vd5HTdq",
        "outputId": "02677247-a2f5-4142-c8c0-826ec57c4961"
      },
      "source": [
        "input_size  = df_train[0][0].size(0)\r\n",
        "hidden_size = 128\r\n",
        "out_size    = 1\r\n",
        "\r\n",
        "Rede_nn = MLP(input_size, hidden_size, out_size).to(args['device'])\r\n",
        "Rede_nn"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (features): Sequential(\n",
              "    (0): Linear(in_features=12, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY6yyywPHk16"
      },
      "source": [
        "criterio = nn.L1Loss().to(args['device'])\r\n",
        "\r\n",
        "optimizer = optim.Adam(Rede_nn.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivgaFjvVHxax"
      },
      "source": [
        "def treinamento(train_loader, net, epoch):\r\n",
        "  net.train()\r\n",
        "  start = time.time()\r\n",
        "  epoch_loss  = []\r\n",
        "\r\n",
        "  for batch in train_loader:\r\n",
        "    \r\n",
        "    dado, rotulo = batch\r\n",
        "    dado = dado.to(args['device'])\r\n",
        "    rotulo = rotulo.to(args['device'])\r\n",
        "    ypred = net(dado)\r\n",
        "    loss = criterio(ypred, rotulo)\r\n",
        "    epoch_loss.append(loss.cpu().data)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "   \r\n",
        "  epoch_loss = np.asarray(epoch_loss)\r\n",
        "  end = time.time()\r\n",
        "  print('#################### Treino ####################')\r\n",
        "  print(f'Epoch {epoch}, Loss: {epoch_loss.mean():.4f} +/- {epoch_loss.std():.4f}, Time: {end-start:.2f}')\r\n",
        "  \r\n",
        "  return epoch_loss.mean()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzNoXgejIN8q"
      },
      "source": [
        "def testar_rede(test_loader, net, epoch):\r\n",
        "\r\n",
        "\r\n",
        "  net.eval()\r\n",
        "  \r\n",
        "  start = time.time()\r\n",
        "  \r\n",
        "  epoch_loss  = []\r\n",
        "  \r\n",
        "  with torch.no_grad(): \r\n",
        "    for batch in test_loader:\r\n",
        "\r\n",
        "      dado, rotulo = batch\r\n",
        "\r\n",
        "      # Cast do dado na GPU\r\n",
        "      dado = dado.to(args['device'])\r\n",
        "      rotulo = rotulo.to(args['device'])\r\n",
        "\r\n",
        "      # Forward\r\n",
        "      ypred = net(dado)\r\n",
        "      loss = criterio(ypred, rotulo)\r\n",
        "      epoch_loss.append(loss.cpu().data)\r\n",
        "\r\n",
        "  epoch_loss = np.asarray(epoch_loss)\r\n",
        "  \r\n",
        "  end = time.time()\r\n",
        "  print('********** Teste **********')\r\n",
        "  print(f'Epoch {epoch}, Loss: {epoch_loss.mean():.4f} +/- {epoch_loss.std():.4f}, Time: {end-start:.2f}')\r\n",
        "  \r\n",
        "  return epoch_loss.mean()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYBYbBfdIQ5E",
        "outputId": "d9358f67-2c56-4111-a48d-28e601395451"
      },
      "source": [
        "for epoca in range(args['epoch_num']):\r\n",
        "  treinamento(train_loader,Rede_nn, epoca)\r\n",
        "  testar_rede(test_loader,Rede_nn, epoca)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#################### Treino ####################\n",
            "Epoch 0, Loss: 164.2516 +/- 44.6484, Time: 2.51\n",
            "********** Teste **********\n",
            "Epoch 0, Loss: 126.1478 +/- 30.5052, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 1, Loss: 130.8727 +/- 25.1582, Time: 2.41\n",
            "********** Teste **********\n",
            "Epoch 1, Loss: 127.0995 +/- 24.2985, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 2, Loss: 122.9428 +/- 30.0363, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 2, Loss: 126.6476 +/- 31.8847, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 3, Loss: 121.4109 +/- 29.8365, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 3, Loss: 116.2783 +/- 26.4167, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 4, Loss: 120.1654 +/- 26.4759, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 4, Loss: 114.2363 +/- 27.8481, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 5, Loss: 119.2547 +/- 32.0881, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 5, Loss: 117.2978 +/- 30.4386, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 6, Loss: 116.7239 +/- 28.3060, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 6, Loss: 119.6345 +/- 26.8727, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 7, Loss: 115.9143 +/- 30.4341, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 7, Loss: 116.3277 +/- 30.4716, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 8, Loss: 113.3911 +/- 27.7305, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 8, Loss: 114.2447 +/- 25.5344, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 9, Loss: 110.0437 +/- 26.9125, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 9, Loss: 108.7961 +/- 28.8317, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 10, Loss: 106.8715 +/- 28.7635, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 10, Loss: 105.3663 +/- 24.7426, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 11, Loss: 102.0281 +/- 25.7801, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 11, Loss: 99.0730 +/- 26.5643, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 12, Loss: 97.7349 +/- 23.3618, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 12, Loss: 94.7438 +/- 24.5966, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 13, Loss: 96.2279 +/- 25.2000, Time: 2.38\n",
            "********** Teste **********\n",
            "Epoch 13, Loss: 94.2756 +/- 23.7008, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 14, Loss: 96.0200 +/- 25.0494, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 14, Loss: 93.6196 +/- 22.9977, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 15, Loss: 94.5267 +/- 24.4622, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 15, Loss: 90.6463 +/- 22.8915, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 16, Loss: 92.3419 +/- 23.8835, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 16, Loss: 89.3775 +/- 22.7261, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 17, Loss: 91.2804 +/- 24.1878, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 17, Loss: 89.1173 +/- 22.7163, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 18, Loss: 91.0898 +/- 24.2860, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 18, Loss: 88.8029 +/- 22.7724, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 19, Loss: 89.6395 +/- 22.8642, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 19, Loss: 87.3112 +/- 21.6331, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 20, Loss: 88.5959 +/- 22.8543, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 20, Loss: 86.3721 +/- 21.9047, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 21, Loss: 87.6385 +/- 21.8673, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 21, Loss: 86.9031 +/- 23.4317, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 22, Loss: 86.9526 +/- 22.9540, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 22, Loss: 85.0966 +/- 22.2925, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 23, Loss: 86.8300 +/- 23.0385, Time: 2.38\n",
            "********** Teste **********\n",
            "Epoch 23, Loss: 87.4287 +/- 21.6353, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 24, Loss: 87.1726 +/- 22.8667, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 24, Loss: 83.8992 +/- 23.3023, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 25, Loss: 86.9635 +/- 23.6913, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 25, Loss: 85.1509 +/- 24.5805, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 26, Loss: 87.2153 +/- 24.2646, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 26, Loss: 87.6226 +/- 25.2116, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 27, Loss: 88.3247 +/- 23.8436, Time: 2.38\n",
            "********** Teste **********\n",
            "Epoch 27, Loss: 82.9835 +/- 23.9917, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 28, Loss: 88.2655 +/- 23.1416, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 28, Loss: 86.7870 +/- 21.0796, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 29, Loss: 86.6077 +/- 23.4667, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 29, Loss: 88.4881 +/- 20.6945, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 30, Loss: 88.3032 +/- 23.4326, Time: 2.39\n",
            "********** Teste **********\n",
            "Epoch 30, Loss: 82.4287 +/- 24.3170, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 31, Loss: 85.7534 +/- 21.8674, Time: 2.41\n",
            "********** Teste **********\n",
            "Epoch 31, Loss: 85.4795 +/- 25.1363, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 32, Loss: 87.9027 +/- 24.2889, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 32, Loss: 89.3073 +/- 20.0838, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 33, Loss: 85.8450 +/- 24.0265, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 33, Loss: 79.7045 +/- 22.1567, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 34, Loss: 85.4717 +/- 21.8851, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 34, Loss: 86.1807 +/- 25.2683, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 35, Loss: 86.8679 +/- 21.9216, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 35, Loss: 88.1801 +/- 20.3063, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 36, Loss: 85.3681 +/- 23.4193, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 36, Loss: 81.8737 +/- 24.4811, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 37, Loss: 84.0656 +/- 21.0607, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 37, Loss: 79.3150 +/- 22.2575, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 38, Loss: 84.3716 +/- 23.9276, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 38, Loss: 81.4191 +/- 20.8469, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 39, Loss: 84.9040 +/- 20.9984, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 39, Loss: 83.2965 +/- 24.5802, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 40, Loss: 84.9238 +/- 23.6503, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 40, Loss: 88.2138 +/- 21.4546, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 41, Loss: 83.2242 +/- 22.8569, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 41, Loss: 84.7053 +/- 24.5631, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 42, Loss: 83.8454 +/- 21.6815, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 42, Loss: 85.5135 +/- 20.0515, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 43, Loss: 81.8340 +/- 22.7984, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 43, Loss: 80.0760 +/- 23.9091, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 44, Loss: 81.1896 +/- 21.4260, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 44, Loss: 77.2317 +/- 21.0207, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 45, Loss: 81.1619 +/- 22.8832, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 45, Loss: 79.2975 +/- 20.3493, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 46, Loss: 80.7546 +/- 20.4523, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 46, Loss: 80.5925 +/- 23.9917, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 47, Loss: 81.3874 +/- 22.0610, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 47, Loss: 82.2439 +/- 20.3555, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 48, Loss: 80.4867 +/- 23.2000, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 48, Loss: 80.0103 +/- 22.6309, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 49, Loss: 80.5341 +/- 19.7455, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 49, Loss: 76.1834 +/- 20.8308, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 50, Loss: 79.5907 +/- 23.0129, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 50, Loss: 77.1320 +/- 21.4443, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 51, Loss: 78.8332 +/- 20.9482, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 51, Loss: 78.1555 +/- 22.4334, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 52, Loss: 78.6012 +/- 21.4918, Time: 2.38\n",
            "********** Teste **********\n",
            "Epoch 52, Loss: 78.6277 +/- 19.8951, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 53, Loss: 77.6266 +/- 21.9615, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 53, Loss: 75.9813 +/- 22.8668, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 54, Loss: 76.5609 +/- 20.9648, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 54, Loss: 74.7723 +/- 21.7496, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 55, Loss: 76.6821 +/- 21.4509, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 55, Loss: 75.8380 +/- 19.9972, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 56, Loss: 75.9469 +/- 22.1830, Time: 2.38\n",
            "********** Teste **********\n",
            "Epoch 56, Loss: 74.3578 +/- 21.4330, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 57, Loss: 75.2213 +/- 20.8825, Time: 2.39\n",
            "********** Teste **********\n",
            "Epoch 57, Loss: 75.8518 +/- 21.5606, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 58, Loss: 74.9908 +/- 20.5207, Time: 2.41\n",
            "********** Teste **********\n",
            "Epoch 58, Loss: 72.6164 +/- 21.6971, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 59, Loss: 74.6650 +/- 21.2787, Time: 2.40\n",
            "********** Teste **********\n",
            "Epoch 59, Loss: 71.8218 +/- 20.7928, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 60, Loss: 74.1245 +/- 21.4705, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 60, Loss: 72.9502 +/- 19.8929, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 61, Loss: 73.1320 +/- 21.4176, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 61, Loss: 72.8511 +/- 20.4013, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 62, Loss: 72.6023 +/- 20.6789, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 62, Loss: 71.2927 +/- 20.2415, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 63, Loss: 72.1619 +/- 20.0346, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 63, Loss: 70.2369 +/- 21.5897, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 64, Loss: 72.0058 +/- 20.8036, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 64, Loss: 71.1532 +/- 21.0224, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 65, Loss: 71.3337 +/- 19.3162, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 65, Loss: 69.9625 +/- 22.0232, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 66, Loss: 71.1454 +/- 22.2412, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 66, Loss: 69.3700 +/- 20.9459, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 67, Loss: 70.4693 +/- 20.6515, Time: 2.43\n",
            "********** Teste **********\n",
            "Epoch 67, Loss: 68.1863 +/- 21.0583, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 68, Loss: 70.3388 +/- 21.0116, Time: 2.39\n",
            "********** Teste **********\n",
            "Epoch 68, Loss: 69.0392 +/- 20.9675, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 69, Loss: 70.4992 +/- 20.1053, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 69, Loss: 68.0814 +/- 20.6847, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 70, Loss: 69.9651 +/- 20.7127, Time: 2.37\n",
            "********** Teste **********\n",
            "Epoch 70, Loss: 67.6009 +/- 20.2802, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 71, Loss: 69.7533 +/- 20.5870, Time: 2.39\n",
            "********** Teste **********\n",
            "Epoch 71, Loss: 68.2885 +/- 20.7835, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 72, Loss: 69.5017 +/- 20.3689, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 72, Loss: 69.6314 +/- 21.2336, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 73, Loss: 70.5445 +/- 19.7153, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 73, Loss: 68.7755 +/- 20.5650, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 74, Loss: 70.2195 +/- 20.9940, Time: 2.45\n",
            "********** Teste **********\n",
            "Epoch 74, Loss: 65.3186 +/- 19.3356, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 75, Loss: 70.0477 +/- 20.2857, Time: 2.54\n",
            "********** Teste **********\n",
            "Epoch 75, Loss: 72.6788 +/- 18.2397, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 76, Loss: 69.9530 +/- 19.6559, Time: 2.50\n",
            "********** Teste **********\n",
            "Epoch 76, Loss: 65.1557 +/- 19.3476, Time: 0.48\n",
            "#################### Treino ####################\n",
            "Epoch 77, Loss: 69.6293 +/- 19.8397, Time: 2.57\n",
            "********** Teste **********\n",
            "Epoch 77, Loss: 70.0726 +/- 20.6766, Time: 0.48\n",
            "#################### Treino ####################\n",
            "Epoch 78, Loss: 68.5825 +/- 17.8260, Time: 2.50\n",
            "********** Teste **********\n",
            "Epoch 78, Loss: 65.7762 +/- 18.9723, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 79, Loss: 67.4143 +/- 20.7189, Time: 2.40\n",
            "********** Teste **********\n",
            "Epoch 79, Loss: 65.9775 +/- 18.3365, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 80, Loss: 66.9053 +/- 19.1281, Time: 2.38\n",
            "********** Teste **********\n",
            "Epoch 80, Loss: 64.7071 +/- 18.5300, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 81, Loss: 66.3990 +/- 19.1937, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 81, Loss: 66.6126 +/- 20.4210, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 82, Loss: 66.7299 +/- 18.8880, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 82, Loss: 65.5466 +/- 19.0780, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 83, Loss: 67.3415 +/- 19.9095, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 83, Loss: 65.7248 +/- 18.3734, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 84, Loss: 66.3370 +/- 19.4651, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 84, Loss: 65.5419 +/- 17.6407, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 85, Loss: 67.1700 +/- 18.6850, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 85, Loss: 65.5184 +/- 19.9287, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 86, Loss: 65.6768 +/- 18.2643, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 86, Loss: 63.7491 +/- 19.1772, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 87, Loss: 65.7169 +/- 19.0810, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 87, Loss: 64.7114 +/- 17.6082, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 88, Loss: 64.9958 +/- 18.6271, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 88, Loss: 63.2614 +/- 17.7680, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 89, Loss: 65.0586 +/- 18.7125, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 89, Loss: 64.5555 +/- 18.9071, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 90, Loss: 64.3764 +/- 17.9703, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 90, Loss: 63.3524 +/- 19.3675, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 91, Loss: 65.2640 +/- 17.9502, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 91, Loss: 63.4465 +/- 17.0445, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 92, Loss: 64.4238 +/- 18.9123, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 92, Loss: 64.7182 +/- 17.4461, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 93, Loss: 65.0117 +/- 18.2835, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 93, Loss: 63.6261 +/- 18.9276, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 94, Loss: 64.0902 +/- 17.0046, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 94, Loss: 62.3467 +/- 18.5790, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 95, Loss: 64.1730 +/- 18.4832, Time: 2.39\n",
            "********** Teste **********\n",
            "Epoch 95, Loss: 64.8346 +/- 17.0877, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 96, Loss: 63.5937 +/- 18.1663, Time: 2.43\n",
            "********** Teste **********\n",
            "Epoch 96, Loss: 61.4236 +/- 17.1851, Time: 0.48\n",
            "#################### Treino ####################\n",
            "Epoch 97, Loss: 64.1398 +/- 18.9994, Time: 2.44\n",
            "********** Teste **********\n",
            "Epoch 97, Loss: 63.4125 +/- 18.4972, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 98, Loss: 62.9683 +/- 17.3746, Time: 2.46\n",
            "********** Teste **********\n",
            "Epoch 98, Loss: 61.6742 +/- 18.2650, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 99, Loss: 62.9481 +/- 17.6549, Time: 2.41\n",
            "********** Teste **********\n",
            "Epoch 99, Loss: 61.8499 +/- 16.8299, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 100, Loss: 62.4313 +/- 17.6581, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 100, Loss: 62.3258 +/- 16.8317, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 101, Loss: 62.2495 +/- 18.4803, Time: 2.36\n",
            "********** Teste **********\n",
            "Epoch 101, Loss: 61.4578 +/- 18.5045, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 102, Loss: 61.6130 +/- 17.5630, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 102, Loss: 61.2886 +/- 17.9921, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 103, Loss: 60.8691 +/- 17.6101, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 103, Loss: 60.1425 +/- 17.4216, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 104, Loss: 60.6772 +/- 18.4078, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 104, Loss: 59.8836 +/- 16.6721, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 105, Loss: 60.3299 +/- 18.1896, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 105, Loss: 59.5873 +/- 16.7688, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 106, Loss: 60.3532 +/- 17.2942, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 106, Loss: 59.4755 +/- 16.4383, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 107, Loss: 60.3654 +/- 17.2363, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 107, Loss: 59.7068 +/- 16.4900, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 108, Loss: 60.2433 +/- 17.3274, Time: 2.40\n",
            "********** Teste **********\n",
            "Epoch 108, Loss: 59.9884 +/- 16.1501, Time: 0.47\n",
            "#################### Treino ####################\n",
            "Epoch 109, Loss: 60.4800 +/- 16.2241, Time: 2.40\n",
            "********** Teste **********\n",
            "Epoch 109, Loss: 60.4614 +/- 16.0979, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 110, Loss: 60.0568 +/- 16.1220, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 110, Loss: 60.6680 +/- 16.0951, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 111, Loss: 60.4060 +/- 16.9674, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 111, Loss: 59.2966 +/- 16.0356, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 112, Loss: 60.3364 +/- 16.2180, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 112, Loss: 59.2355 +/- 16.8779, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 113, Loss: 59.6563 +/- 16.2770, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 113, Loss: 60.0326 +/- 16.7216, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 114, Loss: 59.7142 +/- 17.2253, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 114, Loss: 59.2418 +/- 17.0904, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 115, Loss: 59.5470 +/- 16.1801, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 115, Loss: 59.5057 +/- 16.3021, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 116, Loss: 59.4324 +/- 16.9565, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 116, Loss: 59.5712 +/- 16.7372, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 117, Loss: 59.4685 +/- 16.0776, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 117, Loss: 59.9863 +/- 16.4220, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 118, Loss: 59.4018 +/- 16.8077, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 118, Loss: 59.7479 +/- 16.5907, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 119, Loss: 58.9498 +/- 15.9895, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 119, Loss: 59.9909 +/- 16.4846, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 120, Loss: 58.8298 +/- 16.9848, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 120, Loss: 59.3075 +/- 16.5055, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 121, Loss: 58.8443 +/- 16.9484, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 121, Loss: 60.2846 +/- 17.0519, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 122, Loss: 58.8341 +/- 16.5350, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 122, Loss: 60.5863 +/- 16.9649, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 123, Loss: 58.7048 +/- 16.8263, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 123, Loss: 60.1493 +/- 17.3195, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 124, Loss: 58.2661 +/- 16.4659, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 124, Loss: 59.7105 +/- 16.8096, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 125, Loss: 57.8773 +/- 16.3623, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 125, Loss: 59.1105 +/- 16.9305, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 126, Loss: 58.0108 +/- 14.8683, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 126, Loss: 59.0533 +/- 16.6809, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 127, Loss: 57.6997 +/- 15.6657, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 127, Loss: 58.6302 +/- 16.8441, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 128, Loss: 57.2584 +/- 16.2254, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 128, Loss: 59.0178 +/- 16.7781, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 129, Loss: 57.0963 +/- 16.0968, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 129, Loss: 58.1811 +/- 16.7406, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 130, Loss: 56.9697 +/- 16.0868, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 130, Loss: 58.3994 +/- 16.6184, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 131, Loss: 56.8629 +/- 15.3843, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 131, Loss: 58.2437 +/- 16.5140, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 132, Loss: 56.9721 +/- 16.4162, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 132, Loss: 58.0802 +/- 16.3273, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 133, Loss: 57.0265 +/- 15.4798, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 133, Loss: 59.4339 +/- 16.4753, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 134, Loss: 57.1305 +/- 16.6122, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 134, Loss: 59.7000 +/- 16.5417, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 135, Loss: 57.4443 +/- 16.4631, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 135, Loss: 60.1372 +/- 16.5164, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 136, Loss: 56.9553 +/- 16.0374, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 136, Loss: 60.3663 +/- 16.3404, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 137, Loss: 57.1803 +/- 15.9126, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 137, Loss: 60.8350 +/- 16.5199, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 138, Loss: 57.7581 +/- 16.0718, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 138, Loss: 58.0233 +/- 16.1651, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 139, Loss: 58.3046 +/- 16.4607, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 139, Loss: 60.7917 +/- 17.7235, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 140, Loss: 57.7210 +/- 15.7773, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 140, Loss: 59.0732 +/- 17.3375, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 141, Loss: 59.0971 +/- 16.8904, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 141, Loss: 64.7851 +/- 17.2531, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 142, Loss: 58.2127 +/- 17.6624, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 142, Loss: 57.4017 +/- 16.5162, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 143, Loss: 57.4593 +/- 15.1963, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 143, Loss: 60.0282 +/- 17.1555, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 144, Loss: 58.6768 +/- 16.5577, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 144, Loss: 62.2177 +/- 16.4382, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 145, Loss: 58.0146 +/- 16.6115, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 145, Loss: 58.2642 +/- 16.4757, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 146, Loss: 57.1280 +/- 16.5683, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 146, Loss: 59.2675 +/- 17.5552, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 147, Loss: 58.0179 +/- 15.5200, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 147, Loss: 59.3412 +/- 15.9501, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 148, Loss: 57.9003 +/- 16.4193, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 148, Loss: 57.1532 +/- 15.7889, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 149, Loss: 56.7698 +/- 15.1639, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 149, Loss: 59.5133 +/- 17.6084, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 150, Loss: 57.3661 +/- 15.3422, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 150, Loss: 59.0796 +/- 16.7614, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 151, Loss: 57.3770 +/- 16.7496, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 151, Loss: 58.6634 +/- 15.7545, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 152, Loss: 57.9987 +/- 15.9083, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 152, Loss: 60.3982 +/- 18.1473, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 153, Loss: 58.2684 +/- 16.1081, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 153, Loss: 60.3748 +/- 17.2360, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 154, Loss: 56.5726 +/- 15.0090, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 154, Loss: 57.3113 +/- 16.4667, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 155, Loss: 56.5534 +/- 15.7468, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 155, Loss: 58.4703 +/- 17.5949, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 156, Loss: 56.8793 +/- 16.5910, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 156, Loss: 59.8076 +/- 16.2576, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 157, Loss: 56.8713 +/- 16.4768, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 157, Loss: 56.4439 +/- 16.8383, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 158, Loss: 56.0531 +/- 15.7330, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 158, Loss: 57.8546 +/- 16.8239, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 159, Loss: 57.3893 +/- 15.6894, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 159, Loss: 61.1505 +/- 16.4949, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 160, Loss: 56.7329 +/- 16.5327, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 160, Loss: 57.2763 +/- 16.5097, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 161, Loss: 55.7397 +/- 15.4595, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 161, Loss: 56.2540 +/- 16.0044, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 162, Loss: 55.8592 +/- 16.4446, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 162, Loss: 57.3274 +/- 15.5407, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 163, Loss: 55.4826 +/- 16.0287, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 163, Loss: 56.2870 +/- 15.9685, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 164, Loss: 55.2100 +/- 15.6308, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 164, Loss: 58.1700 +/- 16.7867, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 165, Loss: 54.8950 +/- 15.4711, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 165, Loss: 56.8508 +/- 15.4953, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 166, Loss: 54.6430 +/- 15.3534, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 166, Loss: 57.8275 +/- 16.8355, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 167, Loss: 54.6972 +/- 15.4118, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 167, Loss: 56.4258 +/- 15.4568, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 168, Loss: 54.3668 +/- 14.8506, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 168, Loss: 56.2361 +/- 16.3322, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 169, Loss: 54.3624 +/- 15.7060, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 169, Loss: 55.6778 +/- 16.1814, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 170, Loss: 53.9140 +/- 15.9852, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 170, Loss: 55.4707 +/- 15.7577, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 171, Loss: 54.0439 +/- 15.0294, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 171, Loss: 56.6248 +/- 15.4105, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 172, Loss: 53.9629 +/- 15.0449, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 172, Loss: 56.2754 +/- 16.1777, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 173, Loss: 53.7707 +/- 16.6549, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 173, Loss: 55.4876 +/- 15.7894, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 174, Loss: 53.4740 +/- 15.0574, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 174, Loss: 55.3123 +/- 15.4425, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 175, Loss: 53.0572 +/- 15.3356, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 175, Loss: 54.2770 +/- 15.7775, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 176, Loss: 53.3475 +/- 15.3951, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 176, Loss: 54.4426 +/- 15.5598, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 177, Loss: 53.4802 +/- 14.7533, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 177, Loss: 54.5929 +/- 16.0093, Time: 0.46\n",
            "#################### Treino ####################\n",
            "Epoch 178, Loss: 52.8579 +/- 14.7724, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 178, Loss: 54.3247 +/- 15.7500, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 179, Loss: 52.6675 +/- 14.9896, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 179, Loss: 54.9251 +/- 15.3988, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 180, Loss: 52.9218 +/- 15.5013, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 180, Loss: 54.5207 +/- 15.9508, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 181, Loss: 52.5102 +/- 15.2624, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 181, Loss: 54.0680 +/- 15.5261, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 182, Loss: 52.5630 +/- 15.4917, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 182, Loss: 54.0460 +/- 15.6730, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 183, Loss: 52.2629 +/- 14.1369, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 183, Loss: 53.2962 +/- 15.6651, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 184, Loss: 52.2059 +/- 14.9096, Time: 2.29\n",
            "********** Teste **********\n",
            "Epoch 184, Loss: 53.3698 +/- 15.4657, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 185, Loss: 52.5996 +/- 14.5489, Time: 2.35\n",
            "********** Teste **********\n",
            "Epoch 185, Loss: 53.7704 +/- 15.9061, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 186, Loss: 52.6966 +/- 14.8975, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 186, Loss: 53.5891 +/- 15.8379, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 187, Loss: 52.8918 +/- 15.1039, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 187, Loss: 53.1173 +/- 15.0830, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 188, Loss: 52.7656 +/- 14.1265, Time: 2.29\n",
            "********** Teste **********\n",
            "Epoch 188, Loss: 54.0264 +/- 15.9557, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 189, Loss: 52.6148 +/- 14.6891, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 189, Loss: 52.9487 +/- 15.1282, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 190, Loss: 52.3254 +/- 14.7978, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 190, Loss: 53.3019 +/- 15.5803, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 191, Loss: 51.7489 +/- 14.2354, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 191, Loss: 53.1651 +/- 15.6637, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 192, Loss: 51.7598 +/- 14.4422, Time: 2.32\n",
            "********** Teste **********\n",
            "Epoch 192, Loss: 53.5299 +/- 15.7260, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 193, Loss: 51.4091 +/- 14.7112, Time: 2.29\n",
            "********** Teste **********\n",
            "Epoch 193, Loss: 53.2408 +/- 15.7146, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 194, Loss: 51.5231 +/- 14.8241, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 194, Loss: 53.0680 +/- 16.0409, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 195, Loss: 51.7530 +/- 14.4191, Time: 2.33\n",
            "********** Teste **********\n",
            "Epoch 195, Loss: 53.3187 +/- 15.5090, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 196, Loss: 51.6839 +/- 14.0077, Time: 2.34\n",
            "********** Teste **********\n",
            "Epoch 196, Loss: 52.9662 +/- 15.9294, Time: 0.45\n",
            "#################### Treino ####################\n",
            "Epoch 197, Loss: 51.4436 +/- 14.7326, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 197, Loss: 53.4361 +/- 15.2484, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 198, Loss: 51.8721 +/- 14.2221, Time: 2.31\n",
            "********** Teste **********\n",
            "Epoch 198, Loss: 52.6066 +/- 15.1794, Time: 0.44\n",
            "#################### Treino ####################\n",
            "Epoch 199, Loss: 51.3492 +/- 15.2514, Time: 2.30\n",
            "********** Teste **********\n",
            "Epoch 199, Loss: 52.8472 +/- 15.8337, Time: 0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyGkW4mFLAt0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}